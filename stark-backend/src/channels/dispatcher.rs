use crate::ai::{
    multi_agent::{types::AgentSubtype, Orchestrator, ProcessResult as OrchestratorResult, SubAgentManager},
    AiClient, ArchetypeId, ArchetypeRegistry, AiResponse, Message, MessageRole, ModelArchetype,
    ThinkingLevel, ToolCall, ToolHistoryEntry, ToolResponse,
};
use crate::channels::types::{DispatchResult, NormalizedMessage};
use crate::config::MemoryConfig;
use crate::context::{self, estimate_tokens, ContextManager};
use crate::controllers::api_keys::ApiKeyId;
use crate::db::Database;
use crate::execution::ExecutionTracker;
use crate::gateway::events::EventBroadcaster;
use crate::gateway::protocol::GatewayEvent;
use crate::models::session_message::MessageRole as DbMessageRole;
use crate::models::{AgentSettings, MemoryType, SessionScope};
use crate::tools::{ToolConfig, ToolContext, ToolDefinition, ToolExecution, ToolRegistry};
use chrono::Utc;
use regex::Regex;
use serde_json::Value;
use std::sync::Arc;
use std::time::Duration;
use tokio::time::interval;

/// Maximum number of tool execution iterations
/// Set to 25 to allow for async jobs that require polling (e.g., Bankr API)
const MAX_TOOL_ITERATIONS: usize = 25;

/// How often to broadcast "still waiting" events during long AI calls
const AI_PROGRESS_INTERVAL_SECS: u64 = 30;

/// Configuration for a memory marker pattern
struct MemoryMarkerConfig {
    pattern: Regex,
    memory_type: MemoryType,
    importance: i32,
    name: &'static str,
    use_today_date: bool,
}

impl MemoryMarkerConfig {
    fn new(
        pattern: &str,
        memory_type: MemoryType,
        importance: i32,
        name: &'static str,
        use_today_date: bool,
    ) -> Self {
        Self {
            pattern: Regex::new(pattern).unwrap(),
            memory_type,
            importance,
            name,
            use_today_date,
        }
    }
}

/// Create all memory marker configurations
fn create_memory_markers() -> Vec<MemoryMarkerConfig> {
    vec![
        MemoryMarkerConfig::new(
            r"\[DAILY_LOG:\s*(.+?)\]",
            MemoryType::DailyLog,
            5,
            "daily log",
            true,
        ),
        MemoryMarkerConfig::new(
            r"\[REMEMBER:\s*(.+?)\]",
            MemoryType::LongTerm,
            7,
            "long-term memory",
            false,
        ),
        MemoryMarkerConfig::new(
            r"\[REMEMBER_IMPORTANT:\s*(.+?)\]",
            MemoryType::LongTerm,
            9,
            "important memory",
            false,
        ),
        // Phase 2: New memory types
        MemoryMarkerConfig::new(
            r"\[PREFERENCE:\s*(.+?)\]",
            MemoryType::Preference,
            7,
            "user preference",
            false,
        ),
        MemoryMarkerConfig::new(
            r"\[FACT:\s*(.+?)\]",
            MemoryType::Fact,
            7,
            "user fact",
            false,
        ),
        MemoryMarkerConfig::new(
            r"\[TASK:\s*(.+?)\]",
            MemoryType::Task,
            8,
            "task/commitment",
            true, // Use today's date for tasks
        ),
    ]
}

/// Dispatcher routes messages to the AI and returns responses
pub struct MessageDispatcher {
    db: Arc<Database>,
    broadcaster: Arc<EventBroadcaster>,
    tool_registry: Arc<ToolRegistry>,
    execution_tracker: Arc<ExecutionTracker>,
    burner_wallet_private_key: Option<String>,
    context_manager: ContextManager,
    archetype_registry: ArchetypeRegistry,
    /// Memory marker configurations
    memory_markers: Vec<MemoryMarkerConfig>,
    /// Regex pattern for thinking directives
    thinking_directive_pattern: Regex,
    /// Memory configuration for cross-session and other features
    memory_config: MemoryConfig,
    /// SubAgent manager for spawning background AI agents
    subagent_manager: Option<Arc<SubAgentManager>>,
}

impl MessageDispatcher {
    pub fn new(
        db: Arc<Database>,
        broadcaster: Arc<EventBroadcaster>,
        tool_registry: Arc<ToolRegistry>,
        execution_tracker: Arc<ExecutionTracker>,
    ) -> Self {
        Self::new_with_wallet(db, broadcaster, tool_registry, execution_tracker, None)
    }

    pub fn new_with_wallet(
        db: Arc<Database>,
        broadcaster: Arc<EventBroadcaster>,
        tool_registry: Arc<ToolRegistry>,
        execution_tracker: Arc<ExecutionTracker>,
        burner_wallet_private_key: Option<String>,
    ) -> Self {
        let memory_config = MemoryConfig::from_env();
        let context_manager = ContextManager::new(db.clone())
            .with_memory_config(memory_config.clone());

        // Create SubAgentManager for spawning background AI agents
        let subagent_manager = Arc::new(SubAgentManager::new_with_config(
            db.clone(),
            broadcaster.clone(),
            tool_registry.clone(),
            Default::default(),
            burner_wallet_private_key.clone(),
        ));
        log::info!("[DISPATCHER] SubAgentManager initialized");

        Self {
            db,
            broadcaster,
            tool_registry,
            execution_tracker,
            burner_wallet_private_key,
            context_manager,
            archetype_registry: ArchetypeRegistry::new(),
            memory_markers: create_memory_markers(),
            thinking_directive_pattern: Regex::new(r"(?i)^/(?:t|think|thinking)(?::(\w+))?$").unwrap(),
            memory_config,
            subagent_manager: Some(subagent_manager),
        }
    }

    /// Create a dispatcher without tool support (for backwards compatibility)
    pub fn new_without_tools(db: Arc<Database>, broadcaster: Arc<EventBroadcaster>) -> Self {
        // Create a minimal execution tracker for legacy use
        let execution_tracker = Arc::new(ExecutionTracker::new(broadcaster.clone()));
        let memory_config = MemoryConfig::from_env();
        let context_manager = ContextManager::new(db.clone())
            .with_memory_config(memory_config.clone());
        Self {
            db: db.clone(),
            broadcaster,
            tool_registry: Arc::new(ToolRegistry::new()),
            execution_tracker,
            burner_wallet_private_key: None,
            context_manager,
            archetype_registry: ArchetypeRegistry::new(),
            memory_markers: create_memory_markers(),
            thinking_directive_pattern: Regex::new(r"(?i)^/(?:t|think|thinking)(?::(\w+))?$").unwrap(),
            memory_config,
            subagent_manager: None, // No tools = no subagent support
        }
    }

    /// Dispatch a normalized message to the AI and return the response
    pub async fn dispatch(&self, message: NormalizedMessage) -> DispatchResult {
        // Emit message received event
        self.broadcaster.broadcast(GatewayEvent::channel_message(
            message.channel_id,
            &message.channel_type,
            &message.user_name,
            &message.text,
        ));

        // Check for reset commands
        let text_lower = message.text.trim().to_lowercase();
        if text_lower == "/new" || text_lower == "/reset" {
            return self.handle_reset_command(&message).await;
        }

        // Check for thinking directives (session-level setting)
        if let Some(thinking_response) = self.handle_thinking_directive(&message).await {
            return thinking_response;
        }

        // Parse inline thinking directive and extract clean message
        let (thinking_level, clean_text) = self.parse_inline_thinking(&message.text);

        // Start execution tracking with user message for descriptive display
        let user_msg = clean_text.as_deref().unwrap_or(&message.text);
        let execution_id = self.execution_tracker.start_execution(
            message.channel_id,
            "execute",
            Some(user_msg),
        );

        // Get or create identity for the user
        let identity = match self.db.get_or_create_identity(
            &message.channel_type,
            &message.user_id,
            Some(&message.user_name),
        ) {
            Ok(id) => id,
            Err(e) => {
                log::error!("Failed to get/create identity: {}", e);
                self.execution_tracker.complete_execution(message.channel_id);
                return DispatchResult::error(format!("Identity error: {}", e));
            }
        };

        // Determine session scope (group if chat_id != user_id, otherwise dm)
        let scope = if message.chat_id != message.user_id {
            SessionScope::Group
        } else {
            SessionScope::Dm
        };

        // Get or create chat session
        let session = match self.db.get_or_create_chat_session(
            &message.channel_type,
            message.channel_id,
            &message.chat_id,
            scope,
            None,
        ) {
            Ok(s) => s,
            Err(e) => {
                log::error!("Failed to get/create session: {}", e);
                self.execution_tracker.complete_execution(message.channel_id);
                return DispatchResult::error(format!("Session error: {}", e));
            }
        };

        // Use clean text (with inline thinking directive removed) for storage
        let message_text = clean_text.as_deref().unwrap_or(&message.text);

        // Estimate tokens for the user message
        let user_tokens = estimate_tokens(message_text);

        // Store user message in session with token count
        if let Err(e) = self.db.add_session_message(
            session.id,
            DbMessageRole::User,
            message_text,
            Some(&message.user_id),
            Some(&message.user_name),
            message.message_id.as_deref(),
            Some(user_tokens),
        ) {
            log::error!("Failed to store user message: {}", e);
        } else {
            // Update context tokens
            self.context_manager.update_context_tokens(session.id, user_tokens);
        }

        // Get active agent settings from database, falling back to kimi defaults
        let settings = match self.db.get_active_agent_settings() {
            Ok(Some(settings)) => settings,
            Ok(None) => {
                log::info!("No agent configured, using default kimi settings");
                AgentSettings::default()
            }
            Err(e) => {
                let error = format!("Database error: {}", e);
                log::error!("{}", error);
                self.execution_tracker.complete_execution(message.channel_id);
                return DispatchResult::error(error);
            }
        };

        // Infer archetype from settings
        let archetype_id = AiClient::infer_archetype(&settings);
        log::info!(
            "Using endpoint {} for message dispatch (archetype={}, max_tokens={})",
            settings.endpoint,
            archetype_id,
            settings.max_tokens
        );

        // Create AI client from settings with x402 wallet support
        let client = match AiClient::from_settings_with_wallet(
            &settings,
            self.burner_wallet_private_key.as_deref(),
        ) {
            Ok(c) => c,
            Err(e) => {
                let error = format!("Failed to create AI client: {}", e);
                log::error!("{}", error);
                self.execution_tracker.complete_execution(message.channel_id);
                return DispatchResult::error(error);
            }
        };

        // Add thinking event before AI generation
        self.execution_tracker.add_thinking(message.channel_id, "Processing request...");

        // Get tool configuration for this channel (needed for system prompt)
        let tool_config = self.db.get_effective_tool_config(Some(message.channel_id))
            .unwrap_or_default();

        // Debug: Log tool configuration
        log::info!(
            "[DISPATCH] Tool config - profile: {:?}, allowed_groups: {:?}",
            tool_config.profile,
            tool_config.allowed_groups
        );

        // Build context from memories, tools, skills, and session history
        let system_prompt = self.build_system_prompt(&message, &identity.identity_id, &tool_config);

        // Debug: Log full system prompt
        log::debug!("[DISPATCH] System prompt:\n{}", system_prompt);

        // Get recent session messages for conversation context
        let history = self.db.get_recent_session_messages(session.id, 20).unwrap_or_default();

        // Build messages for the AI
        let mut messages = vec![Message {
            role: MessageRole::System,
            content: system_prompt.clone(),
        }];

        // Add compaction summary if available (provides context from earlier in conversation)
        if let Some(compaction_summary) = self.context_manager.get_compaction_summary(session.id) {
            messages.push(Message {
                role: MessageRole::System,
                content: format!("## Previous Conversation Summary\n{}", compaction_summary),
            });
        }

        // Add conversation history (skip the last one since it's the current message)
        for msg in history.iter().take(history.len().saturating_sub(1)) {
            let role = match msg.role {
                DbMessageRole::User => MessageRole::User,
                DbMessageRole::Assistant => MessageRole::Assistant,
                DbMessageRole::System => MessageRole::System,
            };
            messages.push(Message {
                role,
                content: msg.content.clone(),
            });
        }

        // Add current user message (use clean text without thinking directive)
        messages.push(Message {
            role: MessageRole::User,
            content: message_text.to_string(),
        });

        // Debug: Log user message
        log::info!("[DISPATCH] User message: {}", message_text);

        // Apply thinking level if set (for Claude models)
        if let Some(level) = thinking_level {
            if client.supports_thinking() {
                log::info!("[DISPATCH] Applying thinking level: {}", level);
                client.set_thinking_level(level);
            }
        }

        // Check if the client supports tools and tools are configured
        let use_tools = client.supports_tools() && !self.tool_registry.is_empty();

        // Debug: Log tool availability
        log::info!(
            "[DISPATCH] Tool support - client_supports: {}, registry_count: {}, use_tools: {}",
            client.supports_tools(),
            self.tool_registry.len(),
            use_tools
        );

        // Build tool context with API keys from database
        let workspace_dir = crate::config::workspace_dir();

        let mut tool_context = ToolContext::new()
            .with_channel(message.channel_id, message.channel_type.clone())
            .with_user(message.user_id.clone())
            .with_session(session.id)
            .with_workspace(workspace_dir.clone())
            .with_broadcaster(self.broadcaster.clone())
            .with_database(self.db.clone());

        // Add SubAgentManager for spawning background AI agents
        if let Some(ref manager) = self.subagent_manager {
            tool_context = tool_context.with_subagent_manager(manager.clone());
            log::debug!("[DISPATCH] SubAgentManager attached to tool context");
        }

        // Ensure workspace directory exists
        let _ = std::fs::create_dir_all(&workspace_dir);

        // Load API keys from database for tools that need them
        // Each key is stored individually (e.g., "GITHUB_TOKEN", "DISCORD_BOT_TOKEN")
        // Keys are added to both ToolContext AND environment variables for maximum compatibility
        if let Ok(keys) = self.db.list_api_keys() {
            for key in keys {
                // Add to tool context (for tools that use context.get_api_key)
                tool_context = tool_context.with_api_key(&key.service_name, key.api_key.clone());

                // Also set as environment variables (for tools that use std::env)
                // Use the ApiKeyId to get all env var names for this key
                // SAFETY: We're setting env vars at startup before spawning threads that read them
                if let Some(key_id) = ApiKeyId::from_str(&key.service_name) {
                    if let Some(env_vars) = key_id.env_vars() {
                        for env_var in env_vars {
                            unsafe { std::env::set_var(env_var, &key.api_key); }
                        }
                    }
                }
            }
        }

        // Load bot config from bot_settings for git commits etc.
        if let Ok(bot_settings) = self.db.get_bot_settings() {
            tool_context = tool_context.with_bot_config(bot_settings.bot_name.clone(), bot_settings.bot_email.clone());

            // Add RPC configuration to context for x402_rpc tool
            tool_context.extra.insert(
                "rpc_provider".to_string(),
                serde_json::json!(bot_settings.rpc_provider),
            );
            if let Some(ref endpoints) = bot_settings.custom_rpc_endpoints {
                tool_context.extra.insert(
                    "custom_rpc_endpoints".to_string(),
                    serde_json::json!(endpoints),
                );
            }
        }

        // Generate response with optional tool execution loop
        let final_response = if use_tools {
            self.generate_with_tool_loop(
                &client,
                messages,
                &tool_config,
                &tool_context,
                &identity.identity_id,
                session.id,
                &message,
                archetype_id,
            ).await
        } else {
            // Simple generation without tools - with x402 event emission
            match client.generate_text_with_events(messages, &self.broadcaster, message.channel_id).await {
                Ok((content, payment)) => {
                    // Save x402 payment if one was made
                    if let Some(ref payment_info) = payment {
                        if let Err(e) = self.db.record_x402_payment(
                            Some(message.channel_id),
                            None,
                            payment_info.resource.as_deref(),
                            &payment_info.amount,
                            &payment_info.amount_formatted,
                            &payment_info.asset,
                            &payment_info.pay_to,
                            payment_info.tx_hash.as_deref(),
                            &payment_info.status.to_string(),
                        ) {
                            log::error!("[DISPATCH] Failed to record x402 payment: {}", e);
                        }
                    }
                    Ok(content)
                }
                Err(e) => Err(e),
            }
        };

        match final_response {
            Ok(response) => {
                // Parse and create memories from the response
                self.process_memory_markers(
                    &response,
                    &identity.identity_id,
                    session.id,
                    &message.channel_type,
                    message.message_id.as_deref(),
                );

                // Clean response by removing memory markers before storing/returning
                let clean_response = self.clean_response(&response);

                // Estimate tokens for the response
                let response_tokens = estimate_tokens(&clean_response);

                // Store AI response in session with token count
                if let Err(e) = self.db.add_session_message(
                    session.id,
                    DbMessageRole::Assistant,
                    &clean_response,
                    None,
                    None,
                    None,
                    Some(response_tokens),
                ) {
                    log::error!("Failed to store AI response: {}", e);
                } else {
                    // Update context tokens
                    self.context_manager.update_context_tokens(session.id, response_tokens);

                    // Check if compaction is needed
                    if self.context_manager.needs_compaction(session.id) {
                        log::info!("[COMPACTION] Context limit reached for session {}, triggering compaction", session.id);
                        if let Err(e) = self.context_manager.compact_session(
                            session.id,
                            &client,
                            Some(&identity.identity_id),
                        ).await {
                            log::error!("[COMPACTION] Failed to compact session: {}", e);
                        }
                    }
                }

                // Emit response event
                self.broadcaster.broadcast(GatewayEvent::agent_response(
                    message.channel_id,
                    &message.user_name,
                    &clean_response,
                ));

                log::info!(
                    "Generated response for {} on channel {} using {} archetype",
                    message.user_name,
                    message.channel_id,
                    archetype_id
                );

                // Complete execution tracking
                self.execution_tracker.complete_execution(message.channel_id);

                DispatchResult::success(clean_response)
            }
            Err(e) => {
                let error = format!("AI generation error ({}): {}", archetype_id, e);
                log::error!("{}", error);

                // Complete execution tracking on error
                self.execution_tracker.complete_execution(message.channel_id);

                DispatchResult::error(error)
            }
        }
    }

    /// Generate a response with tool execution loop (supports both native and text-based tool calling)
    /// Now always runs in multi-agent mode with Explore â†’ Plan â†’ Perform flow
    async fn generate_with_tool_loop(
        &self,
        client: &AiClient,
        messages: Vec<Message>,
        tool_config: &ToolConfig,
        tool_context: &ToolContext,
        _identity_id: &str,
        session_id: i64,
        original_message: &NormalizedMessage,
        archetype_id: ArchetypeId,
    ) -> Result<String, String> {
        // Load existing agent context or create new one
        let mut orchestrator = match self.db.get_agent_context(session_id) {
            Ok(Some(context)) => {
                log::info!(
                    "[MULTI_AGENT] Resuming session {} (iteration {})",
                    session_id,
                    context.mode_iterations
                );
                Orchestrator::from_context(context)
            }
            Ok(None) => {
                log::info!(
                    "[MULTI_AGENT] Starting new orchestrator for session {}",
                    session_id
                );
                Orchestrator::new(original_message.text.clone())
            }
            Err(e) => {
                log::warn!(
                    "[MULTI_AGENT] Failed to load context for session {}: {}, starting fresh",
                    session_id, e
                );
                Orchestrator::new(original_message.text.clone())
            }
        };

        // Broadcast initial mode
        let initial_mode = orchestrator.current_mode();
        self.broadcaster.broadcast(GatewayEvent::agent_mode_change(
            original_message.channel_id,
            &initial_mode.to_string(),
            initial_mode.label(),
            Some("Processing request"),
        ));

        // Broadcast initial task state
        self.broadcast_tasks_update(original_message.channel_id, &orchestrator);

        // Get the current subtype
        let subtype = orchestrator.current_subtype();

        log::info!(
            "[MULTI_AGENT] Started in {} mode ({} subtype) for request: {}",
            initial_mode,
            subtype.label(),
            original_message.text.chars().take(50).collect::<String>()
        );

        // Broadcast initial subtype
        self.broadcaster.broadcast(GatewayEvent::agent_subtype_change(
            original_message.channel_id,
            subtype.as_str(),
            subtype.label(),
        ));

        // Get regular tools from registry, filtered by subtype
        // If there's an active skill with requires_tools, force-include those tools
        let mut tools = if let Some(ref active_skill) = orchestrator.context().active_skill {
            if !active_skill.requires_tools.is_empty() {
                log::info!(
                    "[TOOL_LOOP] Active skill '{}' requires tools: {:?}",
                    active_skill.name,
                    active_skill.requires_tools
                );
                self.tool_registry
                    .get_tool_definitions_for_subtype_with_required(
                        tool_config,
                        subtype,
                        &active_skill.requires_tools,
                    )
            } else {
                self.tool_registry.get_tool_definitions_for_subtype(tool_config, subtype)
            }
        } else {
            self.tool_registry.get_tool_definitions_for_subtype(tool_config, subtype)
        };

        // Add skills as a "use_skill" pseudo-tool if any are enabled
        // Skills are also filtered by subtype tags
        if let Some(skill_tool) = self.create_skill_tool_definition_for_subtype(subtype) {
            tools.push(skill_tool);
        }

        // Add orchestrator mode-specific tools
        let mode_tools = orchestrator.get_mode_tools();
        tools.extend(mode_tools);

        // Debug: Log available tools
        log::info!(
            "[TOOL_LOOP] Available tools ({}): {:?}",
            tools.len(),
            tools.iter().map(|t| &t.name).collect::<Vec<_>>()
        );

        // Broadcast toolset update to UI
        self.broadcast_toolset_update(
            original_message.channel_id,
            &orchestrator.current_mode().to_string(),
            orchestrator.current_subtype().as_str(),
            &tools,
        );

        if tools.is_empty() {
            log::warn!("[TOOL_LOOP] No tools available, falling back to text-only generation");
            let (content, payment) = client.generate_text_with_events(messages, &self.broadcaster, original_message.channel_id).await?;
            // Save x402 payment if one was made
            if let Some(ref payment_info) = payment {
                if let Err(e) = self.db.record_x402_payment(
                    Some(original_message.channel_id),
                    None,
                    payment_info.resource.as_deref(),
                    &payment_info.amount,
                    &payment_info.amount_formatted,
                    &payment_info.asset,
                    &payment_info.pay_to,
                    payment_info.tx_hash.as_deref(),
                    &payment_info.status.to_string(),
                ) {
                    log::error!("[TOOL_LOOP] Failed to record x402 payment: {}", e);
                }
            }
            return Ok(content);
        }

        // Get the archetype for this request
        let archetype = self.archetype_registry.get(archetype_id)
            .unwrap_or_else(|| self.archetype_registry.default_archetype());

        log::info!(
            "[TOOL_LOOP] Using archetype: {} (native_tool_calling: {})",
            archetype.id(),
            archetype.uses_native_tool_calling()
        );

        // Branch based on archetype type
        if archetype.uses_native_tool_calling() {
            self.generate_with_native_tools_orchestrated(
                client, messages, tools, tool_config, tool_context,
                original_message, archetype, &mut orchestrator, session_id
            ).await
        } else {
            self.generate_with_text_tools_orchestrated(
                client, messages, tools, tool_config, tool_context,
                original_message, archetype, &mut orchestrator, session_id
            ).await
        }
    }

    /// Broadcast the current toolset to the UI for debug panel visibility
    fn broadcast_toolset_update(
        &self,
        channel_id: i64,
        mode: &str,
        subtype: &str,
        tools: &[ToolDefinition],
    ) {
        let tool_summaries: Vec<serde_json::Value> = tools
            .iter()
            .map(|t| {
                serde_json::json!({
                    "name": t.name,
                    "description": t.description,
                    "group": format!("{:?}", t.group),
                })
            })
            .collect();

        self.broadcaster.broadcast(GatewayEvent::agent_toolset_update(
            channel_id,
            mode,
            subtype,
            tool_summaries,
        ));
    }

    /// Create a "use_skill" tool definition if skills are enabled
    fn create_skill_tool_definition(&self) -> Option<ToolDefinition> {
        // Default to Finance subtype for backwards compatibility
        self.create_skill_tool_definition_for_subtype(AgentSubtype::Finance)
    }

    /// Create a "use_skill" tool definition filtered by agent subtype
    fn create_skill_tool_definition_for_subtype(
        &self,
        subtype: AgentSubtype,
    ) -> Option<ToolDefinition> {
        use crate::tools::{PropertySchema, ToolGroup, ToolInputSchema};

        let skills = self.db.list_enabled_skills().ok()?;
        let allowed_tags = subtype.allowed_skill_tags();

        // Filter skills by subtype tags
        let active_skills: Vec<_> = skills
            .iter()
            .filter(|s| {
                s.enabled
                    && s.tags
                        .iter()
                        .any(|t| allowed_tags.contains(&t.as_str()))
            })
            .collect();

        if active_skills.is_empty() {
            return None;
        }

        let skill_names: Vec<String> = active_skills.iter().map(|s| s.name.clone()).collect();

        let mut properties = std::collections::HashMap::new();
        properties.insert(
            "skill_name".to_string(),
            PropertySchema {
                schema_type: "string".to_string(),
                description: format!("The skill to execute. Options: {}", skill_names.join(", ")),
                default: None,
                items: None,
                enum_values: Some(skill_names),
            },
        );
        properties.insert(
            "input".to_string(),
            PropertySchema {
                schema_type: "string".to_string(),
                description: "Input or query for the skill".to_string(),
                default: None,
                items: None,
                enum_values: None,
            },
        );

        // Format skill descriptions with newlines for better readability
        let formatted_skills = active_skills
            .iter()
            .map(|s| format!("  - {}: {}", s.name, s.description))
            .collect::<Vec<_>>()
            .join("\n");

        Some(ToolDefinition {
            name: "use_skill".to_string(),
            description: format!(
                "Execute a specialized skill. YOU MUST use this tool when a user asks for something that matches a skill.\n\nAvailable skills:\n{}",
                formatted_skills
            ),
            input_schema: ToolInputSchema {
                schema_type: "object".to_string(),
                properties,
                required: vec!["skill_name".to_string(), "input".to_string()],
            },
            group: ToolGroup::System,
        })
    }

    /// Broadcast status update event for the debug panel
    fn broadcast_tasks_update(&self, channel_id: i64, orchestrator: &Orchestrator) {
        let context = orchestrator.context();
        let mode = context.mode;

        // Send simplified status (no task list anymore)
        let stats_json = serde_json::json!({
            "iterations": context.mode_iterations,
            "total_iterations": context.total_iterations,
            "notes_count": context.exploration_notes.len()
        });

        self.broadcaster.broadcast(GatewayEvent::agent_tasks_update(
            channel_id,
            &mode.to_string(),
            mode.label(),
            serde_json::json!([]), // Empty tasks array
            stats_json,
        ));
    }

    /// Generate response using native API tool calling with multi-agent orchestration
    async fn generate_with_native_tools_orchestrated(
        &self,
        client: &AiClient,
        messages: Vec<Message>,
        mut tools: Vec<ToolDefinition>,
        tool_config: &ToolConfig,
        tool_context: &ToolContext,
        original_message: &NormalizedMessage,
        archetype: &dyn ModelArchetype,
        orchestrator: &mut Orchestrator,
        session_id: i64,
    ) -> Result<String, String> {
        // Build conversation with orchestrator's system prompt prepended
        let mut conversation = messages.clone();
        if let Some(system_msg) = conversation.first_mut() {
            if system_msg.role == MessageRole::System {
                // Prepend orchestrator context to the existing system prompt
                let orchestrator_prompt = orchestrator.get_system_prompt();
                system_msg.content = format!(
                    "{}\n\n---\n\n{}",
                    orchestrator_prompt,
                    archetype.enhance_system_prompt(&system_msg.content, &tools)
                );
            }
        }

        // Clear waiting_for_user_context now that it's been consumed into the prompt
        orchestrator.clear_waiting_for_user_context();

        let mut tool_history: Vec<ToolHistoryEntry> = Vec::new();
        let mut iterations = 0;
        let mut tool_call_log: Vec<String> = Vec::new();
        let mut orchestrator_complete = false;
        let mut final_summary = String::new();
        let mut waiting_for_user_response = false;
        let mut user_question_content = String::new();

        loop {
            iterations += 1;
            log::info!(
                "[ORCHESTRATED_LOOP] Iteration {} in {} mode",
                iterations,
                orchestrator.current_mode()
            );

            // Check if execution was cancelled (e.g., user sent /new)
            if self.execution_tracker.is_cancelled(original_message.channel_id) {
                log::info!("[ORCHESTRATED_LOOP] Execution cancelled by user, stopping loop");
                break;
            }

            if iterations > MAX_TOOL_ITERATIONS {
                log::warn!("Orchestrated tool loop exceeded max iterations ({})", MAX_TOOL_ITERATIONS);
                break;
            }

            // Check for forced mode transition
            if let Some(transition) = orchestrator.check_forced_transition() {
                log::info!(
                    "[ORCHESTRATOR] Forced transition: {} â†’ {} ({})",
                    transition.from, transition.to, transition.reason
                );
                self.broadcaster.broadcast(GatewayEvent::agent_mode_change(
                    original_message.channel_id,
                    &transition.to.to_string(),
                    transition.to.label(),
                    Some(&transition.reason),
                ));

                // Update tools for new mode (using current subtype)
                let subtype = orchestrator.current_subtype();
                tools = self
                    .tool_registry
                    .get_tool_definitions_for_subtype(tool_config, subtype);
                if let Some(skill_tool) = self.create_skill_tool_definition_for_subtype(subtype) {
                    tools.push(skill_tool);
                }
                tools.extend(orchestrator.get_mode_tools());

                // Broadcast toolset update
                self.broadcast_toolset_update(
                    original_message.channel_id,
                    &transition.to.to_string(),
                    subtype.as_str(),
                    &tools,
                );

                // Update system prompt for new mode
                if let Some(system_msg) = conversation.first_mut() {
                    if system_msg.role == MessageRole::System {
                        let orchestrator_prompt = orchestrator.get_system_prompt();
                        system_msg.content = format!(
                            "{}\n\n---\n\n{}",
                            orchestrator_prompt,
                            archetype.enhance_system_prompt(&messages[0].content, &tools)
                        );
                    }
                }
            }

            // Generate with native tool support and progress notifications
            let ai_response = self.generate_with_progress(
                &client,
                conversation.clone(),
                tool_history.clone(),
                tools.clone(),
                original_message.channel_id,
            ).await?;

            log::info!(
                "[ORCHESTRATED_LOOP] Response - content_len: {}, tool_calls: {}",
                ai_response.content.len(),
                ai_response.tool_calls.len()
            );

            // Handle x402 payments
            if let Some(ref payment_info) = ai_response.x402_payment {
                self.broadcaster.broadcast(GatewayEvent::x402_payment(
                    original_message.channel_id,
                    &payment_info.amount,
                    &payment_info.amount_formatted,
                    &payment_info.asset,
                    &payment_info.pay_to,
                    payment_info.resource.as_deref(),
                ));
                let _ = self.db.record_x402_payment(
                    Some(original_message.channel_id),
                    None,
                    payment_info.resource.as_deref(),
                    &payment_info.amount,
                    &payment_info.amount_formatted,
                    &payment_info.asset,
                    &payment_info.pay_to,
                    payment_info.tx_hash.as_deref(),
                    &payment_info.status.to_string(),
                );
            }

            // If no tool calls, check if this is allowed
            if ai_response.tool_calls.is_empty() {
                // Check if the agent should have called tools but didn't
                if let Some((warning_msg, attempt)) = orchestrator.check_tool_call_required() {
                    log::warn!(
                        "[ORCHESTRATED_LOOP] Agent skipped tool calls (attempt {}/5), forcing back into loop",
                        attempt
                    );

                    // Broadcast warning to UI so user has visibility
                    self.broadcaster.broadcast(GatewayEvent::agent_warning(
                        original_message.channel_id,
                        "no_tool_calls",
                        &format!(
                            "Agent tried to respond without calling tools (attempt {}/5). Forcing retry...",
                            attempt
                        ),
                        attempt,
                    ));

                    // Add a system message telling the agent to call tools
                    conversation.push(Message {
                        role: MessageRole::Assistant,
                        content: ai_response.content.clone(),
                    });
                    conversation.push(Message {
                        role: MessageRole::User,
                        content: format!(
                            "[SYSTEM ERROR] {}\n\nYou MUST call tools to gather information. Do not respond with made-up data.",
                            warning_msg
                        ),
                    });

                    // Continue the loop to force tool calling
                    continue;
                }

                if orchestrator_complete {
                    let response = if tool_call_log.is_empty() {
                        format!("{}\n\n{}", final_summary, ai_response.content)
                    } else {
                        let tool_log_text = tool_call_log.join("\n");
                        format!("{}\n\n{}\n\n{}", tool_log_text, final_summary, ai_response.content)
                    };
                    return Ok(response);
                } else {
                    // No tool calls but not complete - return content as-is
                    if tool_call_log.is_empty() {
                        return Ok(ai_response.content);
                    } else {
                        let tool_log_text = tool_call_log.join("\n");
                        return Ok(format!("{}\n\n{}", tool_log_text, ai_response.content));
                    }
                }
            }

            // Process tool calls
            let mut tool_responses = Vec::new();
            for call in &ai_response.tool_calls {
                let args_pretty = serde_json::to_string_pretty(&call.arguments)
                    .unwrap_or_else(|_| call.arguments.to_string());

                log::info!(
                    "[TOOL_CALL] Agent calling tool '{}' with args:\n{}",
                    call.name,
                    args_pretty
                );

                tool_call_log.push(format!(
                    "ðŸ”§ **Tool Call:** `{}`\n```json\n{}\n```",
                    call.name,
                    args_pretty
                ));

                self.broadcaster.broadcast(GatewayEvent::agent_tool_call(
                    original_message.channel_id,
                    &call.name,
                    &call.arguments,
                ));

                // Check if this is an orchestrator tool
                let orchestrator_result = orchestrator.process_tool_result(&call.name, &call.arguments);

                match orchestrator_result {
                    OrchestratorResult::Complete(summary) => {
                        log::info!("[ORCHESTRATOR] Execution complete: {}", summary);
                        orchestrator_complete = true;
                        final_summary = summary.clone();
                        tool_responses.push(ToolResponse::success(
                            call.id.clone(),
                            format!("Execution complete: {}", summary),
                        ));
                    }
                    OrchestratorResult::ToolResult(result) => {
                        tool_responses.push(ToolResponse::success(call.id.clone(), result));
                    }
                    OrchestratorResult::Error(err) => {
                        tool_responses.push(ToolResponse::error(call.id.clone(), err));
                    }
                    OrchestratorResult::Continue => {
                        // Not an orchestrator tool, execute normally
                        let result = if call.name == "use_skill" {
                            // Execute skill and set active skill on orchestrator
                            let skill_result = self.execute_skill_tool(&call.arguments, Some(session_id)).await;

                            // Also set active skill directly on orchestrator (in-memory)
                            if skill_result.success {
                                if let Some(skill_name) = call.arguments.get("skill_name").and_then(|v| v.as_str()) {
                                    if let Ok(Some(skill)) = self.db.get_enabled_skill_by_name(skill_name) {
                                        let skills_dir = crate::config::skills_dir();
                                        let skill_base_dir = format!("{}/{}", skills_dir, skill.name);
                                        let instructions = skill.body.replace("{baseDir}", &skill_base_dir);

                                        let requires_tools = skill.requires_tools.clone();
                                        log::info!(
                                            "[SKILL] Activating skill '{}' with requires_tools: {:?}",
                                            skill.name,
                                            requires_tools
                                        );

                                        orchestrator.context_mut().active_skill = Some(crate::ai::multi_agent::types::ActiveSkill {
                                            name: skill.name,
                                            instructions,
                                            activated_at: chrono::Utc::now().to_rfc3339(),
                                            tool_calls_made: 0,
                                            requires_tools: requires_tools.clone(),
                                        });

                                        // Force-include required tools in the toolset
                                        if !requires_tools.is_empty() {
                                            let subtype = orchestrator.current_subtype();
                                            tools = self.tool_registry
                                                .get_tool_definitions_for_subtype_with_required(
                                                    tool_config,
                                                    subtype,
                                                    &requires_tools,
                                                );
                                            if let Some(skill_tool) = self.create_skill_tool_definition_for_subtype(subtype) {
                                                tools.push(skill_tool);
                                            }
                                            tools.extend(orchestrator.get_mode_tools());
                                            log::info!(
                                                "[SKILL] Refreshed toolset with {} tools (including {} required by skill)",
                                                tools.len(),
                                                requires_tools.len()
                                            );
                                        }
                                    }
                                }
                            }
                            skill_result
                        } else {
                            // Execute regular tool and record the call for skill tracking
                            let tool_result = self.tool_registry
                                .execute(&call.name, call.arguments.clone(), tool_context, Some(tool_config))
                                .await;

                            // Record this tool call for active skill tracking
                            if tool_result.success {
                                orchestrator.record_tool_call(&call.name);
                            }

                            tool_result
                        };

                        // Handle subtype change: update orchestrator and refresh tools
                        if call.name == "set_agent_subtype" && result.success {
                            if let Some(subtype_str) = call.arguments.get("subtype").and_then(|v| v.as_str()) {
                                if let Some(new_subtype) = AgentSubtype::from_str(subtype_str) {
                                    orchestrator.set_subtype(new_subtype);
                                    log::info!(
                                        "[SUBTYPE] Changed to {} mode",
                                        new_subtype.label()
                                    );

                                    // Refresh tools for new subtype
                                    tools = self
                                        .tool_registry
                                        .get_tool_definitions_for_subtype(tool_config, new_subtype);
                                    if let Some(skill_tool) =
                                        self.create_skill_tool_definition_for_subtype(new_subtype)
                                    {
                                        tools.push(skill_tool);
                                    }
                                    tools.extend(orchestrator.get_mode_tools());

                                    // Broadcast toolset update
                                    self.broadcast_toolset_update(
                                        original_message.channel_id,
                                        &orchestrator.current_mode().to_string(),
                                        new_subtype.as_str(),
                                        &tools,
                                    );
                                }
                            }
                        }

                        // Handle retry backoff
                        let result = if let Some(retry_secs) = result.retry_after_secs {
                            self.broadcaster.broadcast(GatewayEvent::tool_waiting(
                                original_message.channel_id,
                                &call.name,
                                retry_secs,
                            ));
                            tokio::time::sleep(std::time::Duration::from_secs(retry_secs)).await;
                            crate::tools::ToolResult::error(format!(
                                "{}\n\nðŸ”„ Paused for {} seconds. Please retry.",
                                result.error.unwrap_or_else(|| "Unknown error".to_string()),
                                retry_secs
                            ))
                        } else {
                            result
                        };

                        // Check if this tool requires user response (e.g., ask_user)
                        // If so, we should break the loop after processing to wait for user input
                        if let Some(metadata) = &result.metadata {
                            if metadata.get("requires_user_response").and_then(|v| v.as_bool()).unwrap_or(false) {
                                waiting_for_user_response = true;
                                user_question_content = result.content.clone();
                                log::info!("[ORCHESTRATED_LOOP] Tool requires user response, will break after processing");
                            }
                        }

                        self.broadcaster.broadcast(GatewayEvent::tool_result(
                            original_message.channel_id,
                            &call.name,
                            result.success,
                            0,
                            &result.content,
                        ));

                        tool_responses.push(if result.success {
                            ToolResponse::success(call.id.clone(), result.content)
                        } else {
                            ToolResponse::error(call.id.clone(), result.content)
                        });
                    }
                }

                // Broadcast task list update after any orchestrator tool processing
                self.broadcast_tasks_update(original_message.channel_id, orchestrator);
            }

            // Add to tool history (keep only last N entries to prevent context bloat)
            const MAX_TOOL_HISTORY: usize = 10;
            tool_history.push(ToolHistoryEntry::new(
                ai_response.tool_calls,
                tool_responses,
            ));
            if tool_history.len() > MAX_TOOL_HISTORY {
                // Remove oldest entries, keeping the most recent
                tool_history.drain(0..tool_history.len() - MAX_TOOL_HISTORY);
            }

            // If orchestrator is complete, break the loop
            if orchestrator_complete {
                break;
            }

            // If a tool requires user response (e.g., ask_user), break the loop
            // and return the question content. Context is preserved for when user responds.
            if waiting_for_user_response {
                log::info!("[ORCHESTRATED_LOOP] Breaking loop to wait for user response");
                break;
            }
        }

        // Save orchestrator context for next turn
        if let Err(e) = self.db.save_agent_context(session_id, orchestrator.context()) {
            log::warn!("[MULTI_AGENT] Failed to save context for session {}: {}", session_id, e);
        }

        // Return final response
        if waiting_for_user_response {
            // Save the tool call log to the orchestrator context so the AI knows what it already did
            // This will be included in the system prompt on the next turn
            if !tool_call_log.is_empty() {
                let context_summary = format!(
                    "Before asking the user, I already completed these actions:\n{}",
                    tool_call_log.join("\n")
                );
                orchestrator.context_mut().waiting_for_user_context = Some(context_summary);
                // Re-save context with the waiting_for_user_context
                if let Err(e) = self.db.save_agent_context(session_id, orchestrator.context()) {
                    log::warn!("[MULTI_AGENT] Failed to save context with user_context: {}", e);
                }
            }
            // Return the question content - context is saved, will continue when user responds
            Ok(user_question_content)
        } else if orchestrator_complete {
            Ok(final_summary)
        } else if tool_call_log.is_empty() {
            Err(format!(
                "Tool loop hit max iterations ({}) without completion",
                MAX_TOOL_ITERATIONS
            ))
        } else {
            let tool_log_text = tool_call_log.join("\n");
            Err(format!(
                "Tool loop hit max iterations ({}). Last tool calls:\n{}",
                MAX_TOOL_ITERATIONS,
                tool_log_text
            ))
        }
    }

    /// Generate response using text-based tool calling with multi-agent orchestration
    async fn generate_with_text_tools_orchestrated(
        &self,
        client: &AiClient,
        messages: Vec<Message>,
        mut tools: Vec<ToolDefinition>,
        tool_config: &ToolConfig,
        tool_context: &ToolContext,
        original_message: &NormalizedMessage,
        archetype: &dyn ModelArchetype,
        orchestrator: &mut Orchestrator,
        session_id: i64,
    ) -> Result<String, String> {
        // Build conversation with orchestrator's system prompt
        let mut conversation = messages.clone();
        if let Some(system_msg) = conversation.first_mut() {
            if system_msg.role == MessageRole::System {
                let orchestrator_prompt = orchestrator.get_system_prompt();
                system_msg.content = format!(
                    "{}\n\n---\n\n{}",
                    orchestrator_prompt,
                    archetype.enhance_system_prompt(&system_msg.content, &tools)
                );
            }
        }

        // Clear waiting_for_user_context now that it's been consumed into the prompt
        orchestrator.clear_waiting_for_user_context();

        let mut final_response = String::new();
        let mut iterations = 0;
        let mut tool_call_log: Vec<String> = Vec::new();
        let mut orchestrator_complete = false;
        let mut waiting_for_user_response = false;
        let mut user_question_content = String::new();

        loop {
            iterations += 1;
            log::info!(
                "[TEXT_ORCHESTRATED] Iteration {} in {} mode",
                iterations,
                orchestrator.current_mode()
            );

            // Check if execution was cancelled (e.g., user sent /new)
            if self.execution_tracker.is_cancelled(original_message.channel_id) {
                log::info!("[TEXT_ORCHESTRATED] Execution cancelled by user, stopping loop");
                break;
            }

            if iterations > MAX_TOOL_ITERATIONS {
                log::warn!("Text orchestrated loop exceeded max iterations ({})", MAX_TOOL_ITERATIONS);
                break;
            }

            // Check for forced mode transition
            if let Some(transition) = orchestrator.check_forced_transition() {
                self.broadcaster.broadcast(GatewayEvent::agent_mode_change(
                    original_message.channel_id,
                    &transition.to.to_string(),
                    transition.to.label(),
                    Some(&transition.reason),
                ));

                // Update tools (using current subtype)
                let subtype = orchestrator.current_subtype();
                tools = self
                    .tool_registry
                    .get_tool_definitions_for_subtype(tool_config, subtype);
                if let Some(skill_tool) = self.create_skill_tool_definition_for_subtype(subtype) {
                    tools.push(skill_tool);
                }
                tools.extend(orchestrator.get_mode_tools());

                // Broadcast toolset update
                self.broadcast_toolset_update(
                    original_message.channel_id,
                    &transition.to.to_string(),
                    subtype.as_str(),
                    &tools,
                );

                // Update system prompt
                if let Some(system_msg) = conversation.first_mut() {
                    if system_msg.role == MessageRole::System {
                        let orchestrator_prompt = orchestrator.get_system_prompt();
                        system_msg.content = format!(
                            "{}\n\n---\n\n{}",
                            orchestrator_prompt,
                            archetype.enhance_system_prompt(&messages[0].content, &tools)
                        );
                    }
                }
            }

            let (ai_content, payment) = client.generate_text_with_events(
                conversation.clone(),
                &self.broadcaster,
                original_message.channel_id,
            ).await?;

            if let Some(ref payment_info) = payment {
                let _ = self.db.record_x402_payment(
                    Some(original_message.channel_id),
                    None,
                    payment_info.resource.as_deref(),
                    &payment_info.amount,
                    &payment_info.amount_formatted,
                    &payment_info.asset,
                    &payment_info.pay_to,
                    payment_info.tx_hash.as_deref(),
                    &payment_info.status.to_string(),
                );
            }

            let parsed = archetype.parse_response(&ai_content);

            match parsed {
                Some(agent_response) => {
                    if let Some(tool_call) = agent_response.tool_call {
                        let args_pretty = serde_json::to_string_pretty(&tool_call.tool_params)
                            .unwrap_or_else(|_| tool_call.tool_params.to_string());

                        tool_call_log.push(format!(
                            "ðŸ”§ **Tool Call:** `{}`\n```json\n{}\n```",
                            tool_call.tool_name,
                            args_pretty
                        ));

                        self.broadcaster.broadcast(GatewayEvent::agent_tool_call(
                            original_message.channel_id,
                            &tool_call.tool_name,
                            &tool_call.tool_params,
                        ));

                        // Check if orchestrator tool
                        let orchestrator_result = orchestrator.process_tool_result(
                            &tool_call.tool_name,
                            &tool_call.tool_params,
                        );

                        let tool_result_content = match orchestrator_result {
                            OrchestratorResult::Complete(summary) => {
                                orchestrator_complete = true;
                                final_response = summary.clone();
                                format!("Execution complete: {}", summary)
                            }
                            OrchestratorResult::ToolResult(result) => result,
                            OrchestratorResult::Error(err) => format!("Error: {}", err),
                            OrchestratorResult::Continue => {
                                // Execute regular tool
                                let result = if tool_call.tool_name == "use_skill" {
                                    // Execute skill and set active skill on orchestrator
                                    let skill_result = self.execute_skill_tool(&tool_call.tool_params, Some(session_id)).await;

                                    // Also set active skill directly on orchestrator (in-memory)
                                    if skill_result.success {
                                        if let Some(skill_name) = tool_call.tool_params.get("skill_name").and_then(|v| v.as_str()) {
                                            if let Ok(Some(skill)) = self.db.get_enabled_skill_by_name(skill_name) {
                                                let skills_dir = crate::config::skills_dir();
                                                let skill_base_dir = format!("{}/{}", skills_dir, skill.name);
                                                let instructions = skill.body.replace("{baseDir}", &skill_base_dir);

                                                let requires_tools = skill.requires_tools.clone();
                                                log::info!(
                                                    "[SKILL] Activating skill '{}' with requires_tools: {:?}",
                                                    skill.name,
                                                    requires_tools
                                                );

                                                orchestrator.context_mut().active_skill = Some(crate::ai::multi_agent::types::ActiveSkill {
                                                    name: skill.name,
                                                    instructions,
                                                    activated_at: chrono::Utc::now().to_rfc3339(),
                                                    tool_calls_made: 0,
                                                    requires_tools: requires_tools.clone(),
                                                });

                                                // Force-include required tools in the toolset
                                                if !requires_tools.is_empty() {
                                                    let subtype = orchestrator.current_subtype();
                                                    tools = self.tool_registry
                                                        .get_tool_definitions_for_subtype_with_required(
                                                            tool_config,
                                                            subtype,
                                                            &requires_tools,
                                                        );
                                                    if let Some(skill_tool) = self.create_skill_tool_definition_for_subtype(subtype) {
                                                        tools.push(skill_tool);
                                                    }
                                                    tools.extend(orchestrator.get_mode_tools());
                                                    log::info!(
                                                        "[SKILL] Refreshed toolset with {} tools (including {} required by skill)",
                                                        tools.len(),
                                                        requires_tools.len()
                                                    );
                                                }
                                            }
                                        }
                                    }
                                    skill_result
                                } else {
                                    // Execute regular tool and record the call for skill tracking
                                    let tool_result = self.tool_registry.execute(
                                        &tool_call.tool_name,
                                        tool_call.tool_params.clone(),
                                        tool_context,
                                        Some(tool_config),
                                    ).await;

                                    // Record this tool call for active skill tracking
                                    if tool_result.success {
                                        orchestrator.record_tool_call(&tool_call.tool_name);
                                    }

                                    tool_result
                                };

                                // Handle subtype change: update orchestrator and refresh tools
                                if tool_call.tool_name == "set_agent_subtype" && result.success {
                                    if let Some(subtype_str) = tool_call.tool_params.get("subtype").and_then(|v| v.as_str()) {
                                        if let Some(new_subtype) = AgentSubtype::from_str(subtype_str) {
                                            orchestrator.set_subtype(new_subtype);
                                            log::info!(
                                                "[SUBTYPE] Changed to {} mode",
                                                new_subtype.label()
                                            );

                                            // Refresh tools for new subtype
                                            tools = self
                                                .tool_registry
                                                .get_tool_definitions_for_subtype(tool_config, new_subtype);
                                            if let Some(skill_tool) =
                                                self.create_skill_tool_definition_for_subtype(new_subtype)
                                            {
                                                tools.push(skill_tool);
                                            }
                                            tools.extend(orchestrator.get_mode_tools());

                                            // Broadcast toolset update
                                            self.broadcast_toolset_update(
                                                original_message.channel_id,
                                                &orchestrator.current_mode().to_string(),
                                                new_subtype.as_str(),
                                                &tools,
                                            );
                                        }
                                    }
                                }

                                // Check if this tool requires user response (e.g., ask_user)
                                if let Some(metadata) = &result.metadata {
                                    if metadata.get("requires_user_response").and_then(|v| v.as_bool()).unwrap_or(false) {
                                        waiting_for_user_response = true;
                                        user_question_content = result.content.clone();
                                        log::info!("[TEXT_ORCHESTRATED] Tool requires user response, will break after processing");
                                    }
                                }

                                self.broadcaster.broadcast(GatewayEvent::tool_result(
                                    original_message.channel_id,
                                    &tool_call.tool_name,
                                    result.success,
                                    0,
                                    &result.content,
                                ));

                                result.content
                            }
                        };

                        // Broadcast task list update after any orchestrator tool processing
                        self.broadcast_tasks_update(original_message.channel_id, orchestrator);

                        // Add to conversation
                        conversation.push(Message {
                            role: MessageRole::Assistant,
                            content: ai_content.clone(),
                        });
                        conversation.push(Message {
                            role: MessageRole::User,
                            content: archetype.format_tool_followup(
                                &tool_call.tool_name,
                                &tool_result_content,
                                true,
                            ),
                        });

                        // Truncate conversation to prevent context bloat
                        // Keep system prompt(s) at start + last N message pairs
                        const MAX_CONVERSATION_MESSAGES: usize = 20;
                        let system_count = conversation.iter()
                            .take_while(|m| m.role == MessageRole::System)
                            .count();
                        if conversation.len() > system_count + MAX_CONVERSATION_MESSAGES {
                            let remove_count = conversation.len() - system_count - MAX_CONVERSATION_MESSAGES;
                            conversation.drain(system_count..system_count + remove_count);
                        }

                        if orchestrator_complete {
                            break;
                        }
                        // If a tool requires user response (e.g., ask_user), break the loop
                        if waiting_for_user_response {
                            log::info!("[TEXT_ORCHESTRATED] Breaking loop to wait for user response");
                            break;
                        }
                        continue;
                    } else {
                        // No tool call - check if this is allowed
                        if let Some((warning_msg, attempt)) = orchestrator.check_tool_call_required() {
                            log::warn!(
                                "[TEXT_ORCHESTRATED] Agent skipped tool calls (attempt {}/5), forcing back into loop",
                                attempt
                            );

                            // Broadcast warning to UI so user has visibility
                            self.broadcaster.broadcast(GatewayEvent::agent_warning(
                                original_message.channel_id,
                                "no_tool_calls",
                                &format!(
                                    "Agent tried to respond without calling tools (attempt {}/5). Forcing retry...",
                                    attempt
                                ),
                                attempt,
                            ));

                            // Add messages to force tool calling
                            conversation.push(Message {
                                role: MessageRole::Assistant,
                                content: agent_response.body.clone(),
                            });
                            conversation.push(Message {
                                role: MessageRole::User,
                                content: format!(
                                    "[SYSTEM ERROR] {}\n\nYou MUST call tools to gather information. Do not respond with made-up data.",
                                    warning_msg
                                ),
                            });

                            // Continue the loop to force tool calling
                            continue;
                        }

                        if tool_call_log.is_empty() {
                            final_response = agent_response.body;
                        } else {
                            let tool_log_text = tool_call_log.join("\n");
                            final_response = format!("{}\n\n{}", tool_log_text, agent_response.body);
                        }
                        break;
                    }
                }
                None => {
                    if tool_call_log.is_empty() {
                        final_response = ai_content;
                    } else {
                        let tool_log_text = tool_call_log.join("\n");
                        final_response = format!("{}\n\n{}", tool_log_text, ai_content);
                    }
                    break;
                }
            }
        }

        // Save orchestrator context for next turn
        if let Err(e) = self.db.save_agent_context(session_id, orchestrator.context()) {
            log::warn!("[MULTI_AGENT] Failed to save context for session {}: {}", session_id, e);
        }

        // If waiting for user response, save context and return the question content
        if waiting_for_user_response {
            // Save the tool call log to the orchestrator context so the AI knows what it already did
            if !tool_call_log.is_empty() {
                let context_summary = format!(
                    "Before asking the user, I already completed these actions:\n{}",
                    tool_call_log.join("\n")
                );
                orchestrator.context_mut().waiting_for_user_context = Some(context_summary);
                // Re-save context with the waiting_for_user_context
                if let Err(e) = self.db.save_agent_context(session_id, orchestrator.context()) {
                    log::warn!("[MULTI_AGENT] Failed to save context with user_context: {}", e);
                }
            }
            return Ok(user_question_content);
        }

        if final_response.is_empty() {
            return Err("AI returned empty response".to_string());
        }

        Ok(final_response)
    }

    /// Execute the special "use_skill" tool
    /// If session_id is provided, saves the active skill to the agent context for persistence
    async fn execute_skill_tool(&self, params: &Value, session_id: Option<i64>) -> crate::tools::ToolResult {
        use crate::ai::multi_agent::types::ActiveSkill;

        let skill_name = params.get("skill_name")
            .and_then(|v| v.as_str())
            .unwrap_or("");
        let input = params.get("input")
            .and_then(|v| v.as_str())
            .unwrap_or("");

        log::info!("[SKILL] Executing skill '{}' with input: {}", skill_name, input);

        // Look up the specific skill by name (more efficient than loading all skills)
        let skill = match self.db.get_enabled_skill_by_name(skill_name) {
            Ok(s) => s,
            Err(e) => {
                return crate::tools::ToolResult::error(format!("Failed to load skill: {}", e));
            }
        };

        match skill {
            Some(skill) => {
                // Determine the skills directory path
                let skills_dir = crate::config::skills_dir();
                let skill_base_dir = format!("{}/{}", skills_dir, skill.name);

                // Replace {baseDir} placeholder with actual skill directory
                let instructions = if !skill.body.is_empty() {
                    skill.body.replace("{baseDir}", &skill_base_dir)
                } else {
                    String::new()
                };

                // Save active skill to agent context for persistence
                if let Some(sid) = session_id {
                    if let Ok(Some(mut context)) = self.db.get_agent_context(sid) {
                        context.active_skill = Some(ActiveSkill {
                            name: skill.name.clone(),
                            instructions: instructions.clone(),
                            activated_at: chrono::Utc::now().to_rfc3339(),
                            tool_calls_made: 0, // Reset counter - agent must call actual tools
                            requires_tools: skill.requires_tools.clone(),
                        });
                        if let Err(e) = self.db.save_agent_context(sid, &context) {
                            log::warn!("[SKILL] Failed to save active skill to context: {}", e);
                        } else {
                            log::info!(
                                "[SKILL] Saved active skill '{}' to session {} (tool_calls_made=0, requires_tools={:?})",
                                skill.name, sid, skill.requires_tools
                            );
                        }
                    }
                }

                // Return the skill's instructions/body along with context
                let mut result = format!("## Skill: {}\n\n", skill.name);
                result.push_str(&format!("Description: {}\n\n", skill.description));

                if !instructions.is_empty() {
                    result.push_str("### Instructions:\n");
                    result.push_str(&instructions);
                    result.push_str("\n\n");
                }

                result.push_str(&format!("### User Query:\n{}\n\n", input));
                result.push_str("**IMPORTANT:** Now call the actual tools mentioned in the instructions above. Do NOT call use_skill again.");

                crate::tools::ToolResult::success(&result)
            }
            None => {
                // Fetch available skills for the error message
                let available = self.db.list_enabled_skills()
                    .map(|skills| skills.iter().map(|s| s.name.clone()).collect::<Vec<_>>().join(", "))
                    .unwrap_or_else(|_| "unknown".to_string());
                crate::tools::ToolResult::error(format!(
                    "Skill '{}' not found or not enabled. Available skills: {}",
                    skill_name,
                    available
                ))
            }
        }
    }

    /// Execute a list of tool calls and return responses (for native tool calling)
    async fn execute_tool_calls(
        &self,
        tool_calls: &[ToolCall],
        tool_config: &ToolConfig,
        tool_context: &ToolContext,
        channel_id: i64,
        session_id: i64,
        _user_id: &str,
    ) -> Vec<ToolResponse> {
        let mut responses = Vec::new();

        // Get the current execution ID for tracking
        let execution_id = self.execution_tracker.get_execution_id(channel_id);

        for call in tool_calls {
            let start = std::time::Instant::now();

            // Start tracking this tool execution with context from arguments
            let task_id = if let Some(ref exec_id) = execution_id {
                Some(self.execution_tracker.start_tool(channel_id, exec_id, &call.name, &call.arguments))
            } else {
                None
            };

            // Emit tool execution event (legacy event for backwards compatibility)
            self.broadcaster.broadcast(GatewayEvent::tool_execution(
                channel_id,
                &call.name,
                &call.arguments,
            ));

            // Execute the tool (handle special "use_skill" pseudo-tool)
            let result = if call.name == "use_skill" {
                self.execute_skill_tool(&call.arguments, Some(session_id)).await
            } else {
                self.tool_registry
                    .execute(&call.name, call.arguments.clone(), tool_context, Some(tool_config))
                    .await
            };

            // Handle exponential backoff for retryable errors
            let result = if let Some(retry_secs) = result.retry_after_secs {
                log::info!(
                    "[TOOL_RETRY] Tool '{}' returned retryable error, pausing for {}s before continuing",
                    call.name,
                    retry_secs
                );

                // Emit a waiting event so the UI can show the delay
                self.broadcaster.broadcast(GatewayEvent::tool_waiting(
                    channel_id,
                    &call.name,
                    retry_secs,
                ));

                // Pause for the backoff duration
                tokio::time::sleep(std::time::Duration::from_secs(retry_secs)).await;

                // Return a modified result that instructs the agent to retry
                crate::tools::ToolResult::error(format!(
                    "{}\n\nðŸ”„ The system paused for {} seconds. Please retry the same tool call now - the temporary error may have resolved.",
                    result.error.unwrap_or_else(|| "Unknown error".to_string()),
                    retry_secs
                ))
            } else {
                result
            };

            let duration_ms = start.elapsed().as_millis() as i64;

            // Complete the tool tracking
            if let Some(ref tid) = task_id {
                if result.success {
                    self.execution_tracker.complete_task(tid);
                } else {
                    self.execution_tracker.complete_task_with_error(tid, &result.content);
                }
            }

            // Emit tool result event with content for UI display
            self.broadcaster.broadcast(GatewayEvent::tool_result(
                channel_id,
                &call.name,
                result.success,
                duration_ms,
                &result.content,
            ));

            // Log the execution
            if let Err(e) = self.db.log_tool_execution(&ToolExecution {
                id: None,
                channel_id,
                tool_name: call.name.clone(),
                parameters: call.arguments.clone(),
                success: result.success,
                result: Some(result.content.clone()),
                duration_ms: Some(duration_ms),
                executed_at: Utc::now().to_rfc3339(),
            }) {
                log::error!("Failed to log tool execution: {}", e);
            }

            log::info!(
                "Tool '{}' executed in {}ms, success: {}",
                call.name,
                duration_ms,
                result.success
            );

            // Create tool response
            responses.push(if result.success {
                ToolResponse::success(call.id.clone(), result.content)
            } else {
                ToolResponse::error(call.id.clone(), result.content)
            });
        }

        responses
    }

    /// Load SOUL.md content if it exists
    fn load_soul() -> Option<String> {
        // Try multiple locations for SOUL.md
        let paths = [
            "SOUL.md",
            "./SOUL.md",
            "/app/SOUL.md",
        ];

        for path in paths {
            if let Ok(content) = std::fs::read_to_string(path) {
                log::debug!("[SOUL] Loaded from {}", path);
                return Some(content);
            }
        }

        log::debug!("[SOUL] No SOUL.md found, using default personality");
        None
    }

    /// Build the base system prompt with context from memories and user info
    /// Note: Tool-related instructions are added by the archetype's enhance_system_prompt
    fn build_system_prompt(
        &self,
        message: &NormalizedMessage,
        identity_id: &str,
        _tool_config: &ToolConfig,
    ) -> String {
        let mut prompt = String::new();

        // Load SOUL.md if available, otherwise use default intro
        if let Some(soul) = Self::load_soul() {
            prompt.push_str(&soul);
            prompt.push_str("\n\n");
        } else {
            prompt.push_str("You are StarkBot, an AI agent who can respond to users and operate tools.\n\n");
        }

        // Add daily logs context
        if let Ok(daily_logs) = self.db.get_todays_daily_logs(Some(identity_id)) {
            if !daily_logs.is_empty() {
                prompt.push_str("## Today's Notes\n");
                for log in daily_logs {
                    prompt.push_str(&format!("- {}\n", log.content));
                }
                prompt.push('\n');
            }
        }

        // Add relevant long-term memories
        if let Ok(memories) = self.db.get_long_term_memories(Some(identity_id), Some(5), 10) {
            if !memories.is_empty() {
                prompt.push_str("## User Context\n");
                for mem in memories {
                    prompt.push_str(&format!("- {}\n", mem.content));
                }
                prompt.push('\n');
            }
        }

        // Add recent session summaries (past conversations)
        if let Ok(summaries) = self.db.get_session_summaries(Some(identity_id), 3) {
            if !summaries.is_empty() {
                prompt.push_str("## Previous Sessions\n");
                for summary in summaries {
                    prompt.push_str(&format!("{}\n\n", summary.content));
                }
            }
        }

        // Phase 6: Add cross-session memories from other channels
        if self.memory_config.enable_cross_session_memory {
            if let Ok(cross_memories) = self.db.get_cross_channel_memories(
                identity_id,
                Some(&message.channel_type),
                self.memory_config.cross_session_memory_limit,
            ) {
                if !cross_memories.is_empty() {
                    prompt.push_str("## Context from Other Channels\n");
                    for mem in cross_memories {
                        let channel_label = mem.source_channel_type
                            .as_deref()
                            .unwrap_or("unknown");
                        let type_label = match mem.memory_type {
                            MemoryType::Preference => "preference",
                            MemoryType::Fact => "fact",
                            MemoryType::Task => "task",
                            _ => "memory",
                        };
                        prompt.push_str(&format!("- [{}:{}] {}\n", channel_label, type_label, mem.content));
                    }
                    prompt.push('\n');
                }
            }
        }

        // Add available API keys (so the agent knows what credentials are configured)
        if let Ok(keys) = self.db.list_api_keys() {
            if !keys.is_empty() {
                prompt.push_str("## Available API Keys\n");
                prompt.push_str("The following API keys are configured and available as environment variables when using the exec tool:\n");
                for key in &keys {
                    prompt.push_str(&format!("- ${}\n", key.service_name));
                }
                prompt.push('\n');
            }
        }

        // Add context
        prompt.push_str(&format!(
            "## Current Request\nUser: {} | Channel: {}\n",
            message.user_name, message.channel_type
        ));

        prompt
    }

    /// Process memory markers in the AI response
    fn process_memory_markers(
        &self,
        response: &str,
        identity_id: &str,
        session_id: i64,
        channel_type: &str,
        message_id: Option<&str>,
    ) {
        let today = Utc::now().date_naive();

        for marker in &self.memory_markers {
            for cap in marker.pattern.captures_iter(response) {
                if let Some(content) = cap.get(1) {
                    let content_str = content.as_str().trim();
                    if !content_str.is_empty() {
                        let date = if marker.use_today_date { Some(today) } else { None };
                        if let Err(e) = self.db.create_memory(
                            marker.memory_type.clone(),
                            content_str,
                            None,
                            None,
                            marker.importance,
                            Some(identity_id),
                            Some(session_id),
                            Some(channel_type),
                            message_id,
                            date,
                            None,
                        ) {
                            log::error!("Failed to create {}: {}", marker.name, e);
                        } else {
                            log::info!("Created {}: {}", marker.name, content_str);
                        }
                    }
                }
            }
        }
    }

    /// Remove memory markers from the response before returning to user
    fn clean_response(&self, response: &str) -> String {
        let mut clean = response.to_string();
        for marker in &self.memory_markers {
            clean = marker.pattern.replace_all(&clean, "").to_string();
        }
        // Clean up any double spaces or trailing whitespace
        clean = clean.split_whitespace().collect::<Vec<_>>().join(" ");
        clean.trim().to_string()
    }

    /// Handle thinking directive messages (e.g., "/think:medium" sets session default)
    async fn handle_thinking_directive(&self, message: &NormalizedMessage) -> Option<DispatchResult> {
        let text = message.text.trim();

        // Check if this is a standalone thinking directive
        if let Some(captures) = self.thinking_directive_pattern.captures(text) {
            let level_str = captures.get(1).map(|m| m.as_str()).unwrap_or("low");

            if let Some(level) = ThinkingLevel::from_str(level_str) {
                // Store the thinking level preference for this session
                // For now, we just acknowledge it (session storage could be added later)
                let response = format!(
                    "Thinking level set to **{}**. {}",
                    level,
                    match level {
                        ThinkingLevel::Off => "Extended thinking is now disabled.",
                        ThinkingLevel::Minimal => "Using minimal thinking (~1K tokens).",
                        ThinkingLevel::Low => "Using low thinking (~4K tokens).",
                        ThinkingLevel::Medium => "Using medium thinking (~10K tokens).",
                        ThinkingLevel::High => "Using high thinking (~32K tokens).",
                        ThinkingLevel::XHigh => "Using maximum thinking (~64K tokens).",
                    }
                );

                self.broadcaster.broadcast(GatewayEvent::agent_response(
                    message.channel_id,
                    &message.user_name,
                    &response,
                ));

                log::info!(
                    "Thinking level set to {} for user {} on channel {}",
                    level,
                    message.user_name,
                    message.channel_id
                );

                return Some(DispatchResult::success(response));
            } else {
                // Invalid level specified
                let response = format!(
                    "Invalid thinking level '{}'. Valid options: off, minimal, low, medium, high, xhigh",
                    level_str
                );
                self.broadcaster.broadcast(GatewayEvent::agent_response(
                    message.channel_id,
                    &message.user_name,
                    &response,
                ));
                return Some(DispatchResult::success(response));
            }
        }

        None
    }

    /// Parse inline thinking directive from message (e.g., "/think:high What is...")
    /// Returns the thinking level and the clean message text
    fn parse_inline_thinking(&self, text: &str) -> (Option<ThinkingLevel>, Option<String>) {
        let text = text.trim();

        // Pattern: /think:level followed by the actual message
        let inline_pattern = Regex::new(r"(?i)^/(?:t|think|thinking):(\w+)\s+(.+)$").unwrap();

        if let Some(captures) = inline_pattern.captures(text) {
            let level_str = captures.get(1).map(|m| m.as_str()).unwrap_or("");
            let clean_text = captures.get(2).map(|m| m.as_str().to_string());

            if let Some(level) = ThinkingLevel::from_str(level_str) {
                return (Some(level), clean_text);
            }
        }

        // No inline thinking directive found
        (None, None)
    }

    /// Call AI with progress notifications for long-running requests
    /// Broadcasts "still waiting" events every 30 seconds and handles timeout errors gracefully
    async fn generate_with_progress(
        &self,
        client: &AiClient,
        conversation: Vec<Message>,
        tool_history: Vec<ToolHistoryEntry>,
        tools: Vec<ToolDefinition>,
        channel_id: i64,
    ) -> Result<AiResponse, String> {
        let broadcaster = self.broadcaster.clone();
        let mut elapsed_secs = 0u64;

        // Spawn the actual AI request
        let ai_future = client.generate_with_tools(conversation, tool_history, tools);
        tokio::pin!(ai_future);

        // Create a ticker for progress updates
        let mut progress_ticker = interval(Duration::from_secs(AI_PROGRESS_INTERVAL_SECS));
        progress_ticker.tick().await; // First tick is immediate, skip it

        loop {
            tokio::select! {
                result = &mut ai_future => {
                    match result {
                        Ok(response) => return Ok(response),
                        Err(e) => {
                            // Check if it's a timeout error
                            if e.contains("timed out") || e.contains("timeout") {
                                log::error!("[AI_PROGRESS] Request timed out after {}s: {}", elapsed_secs, e);
                                broadcaster.broadcast(GatewayEvent::agent_error(
                                    channel_id,
                                    &format!("AI request timed out after {} seconds. The AI service may be overloaded. Please try again.", elapsed_secs + AI_PROGRESS_INTERVAL_SECS),
                                ));
                            }
                            return Err(e);
                        }
                    }
                }
                _ = progress_ticker.tick() => {
                    elapsed_secs += AI_PROGRESS_INTERVAL_SECS;
                    log::info!("[AI_PROGRESS] Still waiting for AI response... ({}s elapsed)", elapsed_secs);
                    broadcaster.broadcast(GatewayEvent::agent_thinking(
                        channel_id,
                        &format!("Still thinking... ({}s)", elapsed_secs),
                    ));
                }
            }
        }
    }

    /// Handle /new or /reset commands
    async fn handle_reset_command(&self, message: &NormalizedMessage) -> DispatchResult {
        // Cancel any ongoing execution for this channel
        self.execution_tracker.cancel_execution(message.channel_id);

        // Determine session scope
        let scope = if message.chat_id != message.user_id {
            SessionScope::Group
        } else {
            SessionScope::Dm
        };

        // Get the current session
        match self.db.get_or_create_chat_session(
            &message.channel_type,
            message.channel_id,
            &message.chat_id,
            scope,
            None,
        ) {
            Ok(session) => {
                // Get identity for memory storage
                let identity_id = self.db.get_or_create_identity(
                    &message.channel_type,
                    &message.user_id,
                    Some(&message.user_name),
                ).ok().map(|id| id.identity_id);

                // Save session memory before reset (session memory hook)
                let message_count = self.db.count_session_messages(session.id).unwrap_or(0);
                if message_count >= 2 {
                    // Only save if there are meaningful messages
                    if let Ok(Some(settings)) = self.db.get_active_agent_settings() {
                        if let Ok(client) = AiClient::from_settings(&settings) {
                            match context::save_session_memory(
                                &self.db,
                                &client,
                                session.id,
                                identity_id.as_deref(),
                                15, // Save last 15 messages
                            ).await {
                                Ok(memory_id) => {
                                    log::info!("[SESSION_MEMORY] Saved session memory (id={}) before reset", memory_id);
                                }
                                Err(e) => {
                                    log::warn!("[SESSION_MEMORY] Failed to save session memory: {}", e);
                                }
                            }
                        }
                    }
                }

                // Reset the session
                match self.db.reset_chat_session(session.id) {
                    Ok(_) => {
                        let response = "Session reset. Let's start fresh!".to_string();
                        self.broadcaster.broadcast(GatewayEvent::agent_response(
                            message.channel_id,
                            &message.user_name,
                            &response,
                        ));
                        DispatchResult::success(response)
                    }
                    Err(e) => {
                        log::error!("Failed to reset session: {}", e);
                        DispatchResult::error(format!("Failed to reset session: {}", e))
                    }
                }
            }
            Err(e) => {
                log::error!("Failed to get session for reset: {}", e);
                DispatchResult::error(format!("Session error: {}", e))
            }
        }
    }
}
